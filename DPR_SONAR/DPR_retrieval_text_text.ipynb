{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6af5d324-7aee-4f44-9271-f3757264f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/export/data2/sli/data/MuST-C_synthesized/de/en-de/data/tst_ex_new/txt/tst_ex_new.en') as f:\n",
    "    tst_lines_new=f.readlines()\n",
    "with open('/home/sli/DPR/downloads/data/fairseq/train.en') as f:\n",
    "    train_lines=f.readlines()\n",
    "with open('/export/data2/sli/data/MuST-C_synthesized/de/en-de/data/terminology/txt/terminology.en') as f:\n",
    "    term_lines=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8034215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "\n",
    "\n",
    "def get_audio_path(directory_path):\n",
    "    # List all files in the directory and filter out those that are .wav files\n",
    "    wav_files = [f for f in os.listdir(directory_path) if f.endswith('.wav')]\n",
    "    # Define a function to extract the numeric part from the file name\n",
    "    def extract_number(file_name):\n",
    "        # Split the file name by '_' and take the second part, then remove the '.wav' extension and convert to int\n",
    "        return int(file_name.split('_')[1].replace('.wav', ''))\n",
    "\n",
    "    # Sort the list of files by the numeric part extracted from each file name\n",
    "    sorted_list_by_number = sorted(wav_files, key=extract_number)\n",
    "    audios_path_list = [directory_path+item for item in sorted_list_by_number]\n",
    "\n",
    "    return audios_path_list\n",
    "\n",
    "# Path to the directory containing the .wav files\n",
    "directory_path = '/export/data2/sli/data/MuST-C_synthesized/de/en-de/data/terminology/wav/'\n",
    "term_audio_files=get_audio_path(directory_path)\n",
    "\n",
    "tst_audio_files=get_audio_path('/export/data2/sli/data/MuST-C_synthesized/de/en-de/data/tst_ex_new/wav/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19d6fbd5-4598-4906-8d6a-c56f31089f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8acd809c-2888-4fdd-bd6c-5281f3fddbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_tst_origin=[line.split(' <SEP> ')[1] for line in tst_lines_new]\n",
    "lines_tst_example=[line.split(' <SEP> ')[0] for line in tst_lines_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d692ad4-26d2-4b08-921a-9ea67a68a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from dpr_t5.data.biencoder_data_DPR import BiEncoderPassage\n",
    "from dpr_t5.models import init_biencoder_components\n",
    "from dpr_t5.options import set_cfg_params_from_state, setup_cfg_gpu, setup_logger\n",
    "\n",
    "from dpr_t5.utils.data_utils_DPR import Tensorizer\n",
    "from dpr_t5.utils.model_utils_DPR import (\n",
    "    setup_for_distributed_mode,\n",
    "    get_model_obj,\n",
    "    load_states_from_checkpoint,\n",
    "    move_to_device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce7c2a54-a7d3-4b10-aee7-942f7ee3ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import DictConfig, OmegaConf\n",
    "cfg = OmegaConf.load(\"/home/sli/DPR_t5/conf/gen_embs_DPR.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5481f7ba-4e0a-4e00-848b-3b0d224b9e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'defaults': [{'encoder': 'hf_bert'}, {'ctx_sources': 'default_sources'}], 'model_file': None, 'ctx_src': None, 'encoder_type': 'ctx', 'out_file': None, 'do_lower_case': True, 'shard_id': 0, 'num_shards': 1, 'batch_size': 32, 'tables_as_passages': False, 'special_tokens': None, 'tables_chunk_sz': 100, 'tables_split_type': 'type1', 'local_rank': -1, 'device': None, 'distributed_world_size': None, 'distributed_port': None, 'no_cuda': False, 'n_gpu': None, 'fp16': False, 'fp16_opt_level': 'O1'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2dfae03f-4e75-40e3-88e4-bd9ac246c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.encoder= OmegaConf.load(\"/home/sli/DPR_t5/conf/encoder/hf_bert.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "436ada64-d941-407d-85a4-fc0ef32c4e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'defaults': [{'encoder': 'hf_bert'}, {'ctx_sources': 'default_sources'}], 'model_file': None, 'ctx_src': None, 'encoder_type': 'ctx', 'out_file': None, 'do_lower_case': True, 'shard_id': 0, 'num_shards': 1, 'batch_size': 32, 'tables_as_passages': False, 'special_tokens': None, 'tables_chunk_sz': 100, 'tables_split_type': 'type1', 'local_rank': -1, 'device': None, 'distributed_world_size': None, 'distributed_port': None, 'no_cuda': False, 'n_gpu': None, 'fp16': False, 'fp16_opt_level': 'O1', 'encoder': {'encoder_model_type': 'hf_bert', 'pretrained_model_cfg': 'bert-base-uncased', 'pretrained_file': None, 'projection_dim': 0, 'sequence_length': 256, 'dropout': 0.1, 'fix_ctx_encoder': False, 'pretrained': True}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26b3ac6d-4fd2-4c55-b2c5-59e6b9d8392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 06:15:33,996 [INFO] root: CFG's local_rank=-1\n",
      "2024-02-06 06:15:33,998 [INFO] root: Env WORLD_SIZE=None\n",
      "2024-02-06 06:15:34,000 [INFO] root: Initialized host i13hpc59 as d.rank -1 on device=cuda, n_gpu=1, world size=1\n",
      "2024-02-06 06:15:34,001 [INFO] root: 16-bits training: False \n"
     ]
    }
   ],
   "source": [
    "cfg = setup_cfg_gpu(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f1a6efa-1c0f-42bb-adb3-2201c188a568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 06:15:34,012 [INFO] root: Reading saved model from /home/sli/DPR_t5/results_text_text_DPR/dpr_biencoder.35\n",
      "2024-02-06 06:15:35,849 [INFO] root: model_state_dict keys dict_keys(['model_dict', 'optimizer_dict', 'scheduler_dict', 'offset', 'epoch', 'encoder_params'])\n"
     ]
    }
   ],
   "source": [
    "cfg.model_file='/home/sli/DPR_t5/results_text_text_DPR/dpr_biencoder.35'\n",
    "saved_state = load_states_from_checkpoint(cfg.model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc7a496e-a6ae-4ffe-8a4e-b5128ea19bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_cfg_params_from_state(saved_state.encoder_params, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d7284b8-c8ab-492f-a991-d0eac1e231a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 06:15:35,960 [INFO] dpr_t5.models.hf_models: Initializing HF BERT Encoder. cfg_name=bert-base-uncased\n",
      "2024-02-06 06:15:36,363 [INFO] dpr_t5.models.hf_models: Initializing HF BERT Encoder. cfg_name=bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "tensorizer, encoder, _ = init_biencoder_components(cfg.encoder.encoder_model_type, cfg, inference_only=True)\n",
    "encoder_ctx = encoder.ctx_model\n",
    "encoder_question = encoder.question_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "580cb6a0-5f62-4763-b2b6-f83d674172ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_ctx, _ = setup_for_distributed_mode(\n",
    "        encoder_ctx,\n",
    "        None,\n",
    "        cfg.device,\n",
    "        cfg.n_gpu,\n",
    "        cfg.local_rank,\n",
    "        cfg.fp16,\n",
    "        cfg.fp16_opt_level,\n",
    "    )\n",
    "encoder_question, _ = setup_for_distributed_mode(\n",
    "        encoder_question,\n",
    "        None,\n",
    "        cfg.device,\n",
    "        cfg.n_gpu,\n",
    "        cfg.local_rank,\n",
    "        cfg.fp16,\n",
    "        cfg.fp16_opt_level,\n",
    "    )\n",
    "encoder_ctx.eval()\n",
    "encoder_question.eval()\n",
    "model_to_load_ctx = get_model_obj(encoder_ctx)\n",
    "model_to_load_question = get_model_obj(encoder_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1c43e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_len_ctx = len(\"ctx_model.\")\n",
    "ctx_state = {\n",
    "        key[prefix_len_ctx:]: value for (key, value) in saved_state.model_dict.items() if key.startswith(\"ctx_model.\")\n",
    "    }\n",
    "model_to_load_ctx.load_state_dict(ctx_state, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43bcfd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_len_question = len(\"question_model.\")\n",
    "question_state = {\n",
    "        key[prefix_len_question:]: value for (key, value) in saved_state.model_dict.items() if key.startswith(\"question_model.\")\n",
    "    }\n",
    "model_to_load_question.load_state_dict(question_state, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae5e5014-0abf-40e8-b7a8-ca2d1298e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpr_t5.data.biencoder_data_DPR import BiEncoderPassage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6279ad4f-8a1d-4374-8654-a06b08c6047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_passages=[('term_set',BiEncoderPassage(term_lines[i],'')) for i in range(len(term_lines))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd92066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "model=encoder_ctx\n",
    "insert_title= True\n",
    "for passage in all_passages:\n",
    "    batch=[passage]\n",
    "    batch_token_tensors = [tensorizer.text_to_tensor(ctx[1].text, title=ctx[1].title if insert_title else None) for ctx in batch]\n",
    "    ctx_ids_batch = move_to_device(torch.stack(batch_token_tensors, dim=0), cfg.device)\n",
    "    ctx_seg_batch = move_to_device(torch.zeros_like(ctx_ids_batch), cfg.device)\n",
    "    ctx_attn_mask = move_to_device(tensorizer.get_attn_mask(ctx_ids_batch), cfg.device)\n",
    "    with torch.no_grad():\n",
    "            _, out, _ = model(ctx_ids_batch, ctx_seg_batch, ctx_attn_mask)\n",
    "    out=out.cpu()\n",
    "    results.extend([out[0].view(-1).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5eef211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9821\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "print(len(results))\n",
    "print(results[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7808be6-b1a0-410e-9732-ddc0d408e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_questions=[('tst_set',BiEncoderPassage(lines_tst_origin[i],'')) for i in range(len(lines_tst_origin))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e884607",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_question=[]\n",
    "model=encoder_question\n",
    "for question in all_questions:\n",
    "    batch=[question] \n",
    "    batch_token_tensors = [tensorizer.text_to_tensor(ctx[1].text, title=ctx[1].title if insert_title else None) for ctx in batch]\n",
    "    ctx_ids_batch = move_to_device(torch.stack(batch_token_tensors, dim=0), cfg.device)\n",
    "    ctx_seg_batch = move_to_device(torch.zeros_like(ctx_ids_batch), cfg.device)\n",
    "    ctx_attn_mask = move_to_device(tensorizer.get_attn_mask(ctx_ids_batch), cfg.device)\n",
    "    with torch.no_grad():\n",
    "            _, out, _ = model(ctx_ids_batch, ctx_seg_batch, ctx_attn_mask)\n",
    "    out=out.cpu()\n",
    "    results_question.extend([out[0].view(-1).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11442308-acd4-4e00-bfcd-aa05d8b516c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "print(len(results_question))\n",
    "print(results_question[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bee7f466-7e1d-4159-8900-674e3c6cd043",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_tensors=[torch.unsqueeze(torch.from_numpy(results_question[i]),dim=0) for i in range(len(results_question))]\n",
    "terminology_tensors=[torch.unsqueeze(torch.from_numpy(results[i]),dim=0) for i in range(len(results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3d399bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "print(tst_tensors[0].shape)\n",
    "print(terminology_tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "40268a1b-2484-41af-8269-7a32d33136ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminology_data=torch.cat(terminology_tensors,dim=0)\n",
    "tst_term_pairs=[]\n",
    "#for j,item in enumerate(tst_tensors):\n",
    "#    dist=torch.norm(terminology_data-item,dim=1,p=2)\n",
    "#    knn=dist.topk(5,largest=False)\n",
    "#    #knn.values\n",
    "#    tst_term_pairs.append([j,knn.indices.tolist(),knn.values])\n",
    "for j,item in enumerate(tst_tensors):\n",
    "    dist=torch.matmul(terminology_data,torch.transpose(item,0,1))\n",
    "    dist=torch.transpose(dist,0,1)   \n",
    "    knn=dist.topk(10)\n",
    "    #knn.values\n",
    "    tst_term_pairs.append([j,knn.indices.tolist()[0],knn.values])\n",
    "with open('/home/sli/DPR_t5/retrieve_results/tst_term_pairs_dpr_q_n_p_text_text_10.txt','w') as f:\n",
    "        for item in tst_term_pairs:\n",
    "               f.write('{} \\n'.format(item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e168e86-21dd-4897-882e-8a7994545c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,pair in enumerate(tst_term_pairs):\n",
    "    if i==0:\n",
    "        with open('/home/sli/DPR_t5/retrieve_results/tst_with_retrieved_example_dpr_q_n_p_text_text_1st_NN_3.txt','w') as g: #\n",
    "            g.write(term_lines[pair[1][0]].strip()+' <SEP> '+lines_tst_origin[pair[0]])\n",
    "        with open('/home/sli/DPR_t5/retrieve_results/tst_with_retrieved_example_dpr_q_n_p_text_text_2st_NN_3.txt','w') as g: #\n",
    "            g.write(term_lines[pair[1][1]].strip()+' <SEP> '+lines_tst_origin[pair[0]])\n",
    "        with open('/home/sli/DPR_t5/retrieve_results/tst_with_retrieved_example_dpr_q_n_p_text_text_3st_NN_3.txt','w') as g: #\n",
    "            g.write(term_lines[pair[1][2]].strip()+' <SEP> '+lines_tst_origin[pair[0]])\n",
    "    else:\n",
    "        with open('/home/sli/DPR_t5/retrieve_results/tst_with_retrieved_example_dpr_q_n_p_text_text_1st_NN_3.txt','a') as g: #\n",
    "            g.write(term_lines[pair[1][0]].strip()+' <SEP> '+lines_tst_origin[pair[0]])\n",
    "        with open('/home/sli/DPR_t5/retrieve_results/tst_with_retrieved_example_dpr_q_n_p_text_text_2st_NN_3.txt','a') as g: #\n",
    "            g.write(term_lines[pair[1][1]].strip()+' <SEP> '+lines_tst_origin[pair[0]])\n",
    "        with open('/home/sli/DPR_t5/retrieve_results/tst_with_retrieved_example_dpr_q_n_p_text_text_3st_NN_3.txt','a') as g: #\n",
    "            g.write(term_lines[pair[1][2]].strip()+' <SEP> '+lines_tst_origin[pair[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "806e71fa-d767-424d-a80f-74d3cd23a01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of rare words is 2959\n",
      "num of rare words in example is 1032\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('/home/sli/DPR_t5/retrieve_results/tst_with_retrieved_example_dpr_q_n_p_text_text_1st_NN_3.txt',encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "import json\n",
    "with open('/home/sli/DPR/downloads/data/fairseq/rareword_terminology.txt') as f:\n",
    "    data = f.read()\n",
    "dictionary=json.loads(data)\n",
    "import spacy\n",
    "  \n",
    "nlp=spacy.load(\"en_core_web_sm\") \n",
    "examples=[]\n",
    "sentences=[]\n",
    "for line in lines:\n",
    "    id_sep=line.find(' <SEP> ')\n",
    "    example=line[:id_sep]\n",
    "    sentence=line[id_sep+7:]\n",
    "    examples.append(example)\n",
    "    sentences.append(sentence)\n",
    "sentence_rarewords={}\n",
    "example_rarewords={}\n",
    "\n",
    "for i in range(len(examples)):\n",
    "    line_sentence=sentences[i]\n",
    "    line_example=examples[i]\n",
    "    \n",
    "    sentence_rarewords[i]=[]\n",
    "    example_rarewords[i]=[]\n",
    "    \n",
    "    doc_sentence=nlp(line_sentence)\n",
    "    pred_item_sentence=[token.lemma_.lower() for token in doc_sentence if not token.is_stop and not token.is_punct]\n",
    "    \n",
    "    doc_example=nlp(line_example)\n",
    "    pred_item_example=[token.lemma_.lower() for token in doc_example if not token.is_stop and not token.is_punct]\n",
    "    pred_item_example_new=\" \".join(pred_item_example)\n",
    "    for j,item in enumerate(pred_item_sentence):\n",
    "        try:\n",
    "            dictionary[item]\n",
    "            sentence_rarewords[i].append(item)\n",
    "\n",
    "            if item in pred_item_example_new:\n",
    "                example_rarewords[i].append(item)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "total_rarewords=[]\n",
    "for k,v in sentence_rarewords.items():\n",
    "    total_rarewords=total_rarewords+v\n",
    "    total_rarewords_set=set(total_rarewords)\n",
    "    total_rarewords=list(total_rarewords)\n",
    "    \n",
    "    total_example_rarewords=[]\n",
    "    for k,v in example_rarewords.items():\n",
    "        total_example_rarewords=total_example_rarewords+v\n",
    "    total_example_rarewords_set=set(total_example_rarewords)\n",
    "    total_example_rarewords=list(total_example_rarewords)\n",
    "    \n",
    "print(\"num of rare words is {}\".format(len(total_rarewords))) #num of unrecognized lemma\n",
    "print(\"num of rare words in example is {}\".format(len(total_example_rarewords))) #num of recognized word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "203ca394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of rare words is 2959\n",
      "num of rare words in example is 223\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('/home/sli/DPR_t5/retrieve_results/tst_with_retrieved_example_dpr_q_n_p_text_text_2st_NN_3.txt',encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "import json\n",
    "with open('/home/sli/DPR/downloads/data/fairseq/rareword_terminology.txt') as f:\n",
    "    data = f.read()\n",
    "dictionary=json.loads(data)\n",
    "import spacy\n",
    "  \n",
    "nlp=spacy.load(\"en_core_web_sm\") \n",
    "examples=[]\n",
    "sentences=[]\n",
    "for line in lines:\n",
    "    id_sep=line.find(' <SEP> ')\n",
    "    example=line[:id_sep]\n",
    "    sentence=line[id_sep+7:]\n",
    "    examples.append(example)\n",
    "    sentences.append(sentence)\n",
    "sentence_rarewords={}\n",
    "example_rarewords={}\n",
    "\n",
    "for i in range(len(examples)):\n",
    "    line_sentence=sentences[i]\n",
    "    line_example=examples[i]\n",
    "    \n",
    "    sentence_rarewords[i]=[]\n",
    "    example_rarewords[i]=[]\n",
    "    \n",
    "    doc_sentence=nlp(line_sentence)\n",
    "    pred_item_sentence=[token.lemma_.lower() for token in doc_sentence if not token.is_stop and not token.is_punct]\n",
    "    \n",
    "    doc_example=nlp(line_example)\n",
    "    pred_item_example=[token.lemma_.lower() for token in doc_example if not token.is_stop and not token.is_punct]\n",
    "    pred_item_example_new=\" \".join(pred_item_example)\n",
    "    for j,item in enumerate(pred_item_sentence):\n",
    "        try:\n",
    "            dictionary[item]\n",
    "            sentence_rarewords[i].append(item)\n",
    "\n",
    "            if item in pred_item_example_new:\n",
    "                example_rarewords[i].append(item)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "total_rarewords=[]\n",
    "for k,v in sentence_rarewords.items():\n",
    "    total_rarewords=total_rarewords+v\n",
    "    total_rarewords_set=set(total_rarewords)\n",
    "    total_rarewords=list(total_rarewords)\n",
    "    \n",
    "    total_example_rarewords=[]\n",
    "    for k,v in example_rarewords.items():\n",
    "        total_example_rarewords=total_example_rarewords+v\n",
    "    total_example_rarewords_set=set(total_example_rarewords)\n",
    "    total_example_rarewords=list(total_example_rarewords)\n",
    "    \n",
    "print(\"num of rare words is {}\".format(len(total_rarewords))) #num of unrecognized lemma\n",
    "print(\"num of rare words in example is {}\".format(len(total_example_rarewords))) #num of recognized word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be3636-970c-42a3-a44b-3f4d838b33b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
